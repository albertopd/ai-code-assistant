from google import genai

from utils.prompt_templates import KNOWN_ERROR_PROMPT, UNKNOWN_ERROR_PROMPT


class LlmClient:
    """
    Handles communication with the Language Model (Google Gemini).
    """

    def __init__(self, api_key: str, ai_model: str):
        """
        Initialize the GenAI client.

        Args:
            api_key (str): Google Gemini API key.
            ai_model (str): Model name to use for generation.
        """
        self.client = genai.Client(api_key=api_key)
        self.ai_model = ai_model

    def get_explanation(self, code: str, error: str) -> str:
        """
        Generate a conceptual explanation for the given code and error.

        Args:
            code (str): The code snippet to analyze.
            error (str): The error message (can be empty).

        Returns:
            str: The explanation generated by the LLM.
        """
        if not error.strip():
            prompt = UNKNOWN_ERROR_PROMPT.format(code=code)
        else:
            prompt = KNOWN_ERROR_PROMPT.format(code=code, error=error)

        response = self.client.models.generate_content(
            model=self.ai_model, contents=prompt
        )

        return response.text if response and response.text else "No explanation found."
